{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c76a62f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# GPU check\n",
    "\n",
    "## Check NVIDIA driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c993d00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:50.855038Z",
     "start_time": "2023-04-13T17:18:49.989079Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 11 03:52:53 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  A30                 On   | 00000000:A0:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    29W / 165W |      0MiB / 24258MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e098662",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check GPU in PyTorch\n",
    "### Import PyTorch to check GPU devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bfa0d38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:51.794978Z",
     "start_time": "2023-04-13T17:18:50.852002Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96268b62",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the version of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f00232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:51.827270Z",
     "start_time": "2023-04-13T17:18:51.799271Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.1.1+cu121'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "248cc2d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check if PyTorch can call GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e571e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:51.890823Z",
     "start_time": "2023-04-13T17:18:51.824271Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46e03918",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the number of the GPUs of the computer in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37ff8de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:51.897822Z",
     "start_time": "2023-04-13T17:18:51.854727Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "gpu_num = torch.cuda.device_count()\n",
    "print(gpu_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea613451",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the GPU type of the computer in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8b9a570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:51.897822Z",
     "start_time": "2023-04-13T17:18:51.882725Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(gpu_num):\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGPU \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i, \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_device_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m))\n",
      "File \u001B[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/torch/cuda/__init__.py:419\u001B[0m, in \u001B[0;36mget_device_name\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_device_name\u001B[39m(device: Optional[_device_t] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m    408\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Gets the name of a device.\u001B[39;00m\n\u001B[1;32m    409\u001B[0m \n\u001B[1;32m    410\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;124;03m        str: the name of the device\u001B[39;00m\n\u001B[1;32m    418\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 419\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_device_properties\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mname\n",
      "File \u001B[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/torch/cuda/__init__.py:449\u001B[0m, in \u001B[0;36mget_device_properties\u001B[0;34m(device)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_device_properties\u001B[39m(device: _device_t) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _CudaDeviceProperties:\n\u001B[1;32m    440\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Gets the properties of a device.\u001B[39;00m\n\u001B[1;32m    441\u001B[0m \n\u001B[1;32m    442\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001B[39;00m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 449\u001B[0m     \u001B[43m_lazy_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# will define _get_device_properties\u001B[39;00m\n\u001B[1;32m    450\u001B[0m     device \u001B[38;5;241m=\u001B[39m _get_device_index(device, optional\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count():\n",
      "File \u001B[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/torch/cuda/__init__.py:298\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA_MODULE_LOADING\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39menviron:\n\u001B[1;32m    297\u001B[0m     os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA_MODULE_LOADING\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLAZY\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 298\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001B[39;00m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;66;03m# we need to just return without initializing in that case.\u001B[39;00m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;66;03m# However, we must not let any *other* threads in!\u001B[39;00m\n\u001B[1;32m    302\u001B[0m _tls\u001B[38;5;241m.\u001B[39mis_initializing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "for i in range(gpu_num):\n",
    "    print('GPU {}.: {}'.format(i, torch.cuda.get_device_name(i)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dde8aefb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check GPU in TensorFlow\n",
    "### Import TensorFlow to check GPU devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10df2c49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:53.523525Z",
     "start_time": "2023-04-13T17:18:51.882725Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 07:00:11.650209: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-10 07:00:11.875992: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-10 07:00:11.880518: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-10 07:00:11.880527: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-01-10 07:00:13.325769: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-10 07:00:13.326009: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-10 07:00:13.326014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7161c2a2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the version of TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caffacb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:53.579778Z",
     "start_time": "2023-04-13T17:18:53.526524Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.11.1'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2a4a346",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check if TensorFlow can call GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b273d8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:56.347645Z",
     "start_time": "2023-04-13T17:18:53.578771Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_102977/2294581100.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 07:00:24.050294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-10 07:00:24.102038: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-10 07:00:24.102253: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 07:00:24.102403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 07:00:24.102543: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-01-10 07:00:24.102729: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 07:00:24.102897: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 07:00:24.102945: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa90ea72",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check physical GPUs in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e31ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:56.401645Z",
     "start_time": "2023-04-13T17:18:56.363645Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 07:00:28.619529: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9347be86",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the GPU type of the computer in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "318c3603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:56.457653Z",
     "start_time": "2023-04-13T17:18:56.389649Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 07:00:32.412459: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "for x in local_device_protos:\n",
    "    if x.device_type == 'GPU':\n",
    "        print(x.physical_device_desc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abbbf2db",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check GPU in Jax and jaxlib\n",
    "### Import Jax and jaxlib to check GPU devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "374fe8bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:56.505645Z",
     "start_time": "2023-04-13T17:18:56.419645Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jaxlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16a801b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the version of jax and jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa47eb20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:56.505645Z",
     "start_time": "2023-04-13T17:18:56.505645Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'0.4.12'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eda12a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:56.506646Z",
     "start_time": "2023-04-13T17:18:56.505645Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'0.4.12'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaxlib.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "423a8016",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check all the devices from the default backend of jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f643887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:56.506646Z",
     "start_time": "2023-04-13T17:18:56.505645Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[CpuDevice(id=0)]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbcda938",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the total number of devices of jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7dbdfc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:56.506646Z",
     "start_time": "2023-04-13T17:18:56.505645Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.device_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3b1b71b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the number of JAX processes associated with the backend of jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6847ebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:56.523880Z",
     "start_time": "2023-04-13T17:18:56.505645Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.process_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b89568d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the backend of jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a490cc61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T17:18:56.524833Z",
     "start_time": "2023-04-13T17:18:56.523880Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79e98d71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run a linear regression demo to verify that the Jax can run well\n",
    "The demo code is from [https://www.secretflow.org.cn/docs/secretflow/en/tutorial/lr_with_spu.html](https://www.secretflow.org.cn/docs/secretflow/en/tutorial/lr_with_spu.html)\n",
    "#### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61ce21f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "def breast_cancer(party_id=None, train: bool = True) -> (np.ndarray, np.ndarray):\n",
    "    x, y = load_breast_cancer(return_X_y=True)\n",
    "    x = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    if train:\n",
    "        if party_id:\n",
    "            if party_id == 1:\n",
    "                return x_train[:, :15], _\n",
    "            else:\n",
    "                return x_train[:, 15:], y_train\n",
    "        else:\n",
    "            return x_train, y_train\n",
    "    else:\n",
    "        return x_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5da1e71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c25b432",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + jnp.exp(-x))\n",
    "\n",
    "\n",
    "# Outputs probability of a label being true.\n",
    "def predict(W, b, inputs):\n",
    "    return sigmoid(jnp.dot(inputs, W) + b)\n",
    "\n",
    "\n",
    "# Training loss is the negative log-likelihood of the training examples.\n",
    "def loss(W, b, inputs, targets):\n",
    "    preds = predict(W, b, inputs)\n",
    "    label_probs = preds * targets + (1 - preds) * (1 - targets)\n",
    "    return -jnp.mean(jnp.log(label_probs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee9c7668",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### build train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cd52139",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from jax import grad\n",
    "\n",
    "\n",
    "def train_step(W, b, x1, x2, y, learning_rate):\n",
    "    x = jnp.concatenate([x1, x2], axis=1)\n",
    "    Wb_grad = grad(loss, (0, 1))(W, b, x, y)\n",
    "    W -= learning_rate * Wb_grad[0]\n",
    "    b -= learning_rate * Wb_grad[1]\n",
    "    return W, b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55cc512d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### build fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58800872",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit(W, b, x1, x2, y, epochs=1, learning_rate=1e-2):\n",
    "    for _ in range(epochs):\n",
    "        W, b = train_step(W, b, x1, x2, y, learning_rate=learning_rate)\n",
    "    return W, b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4175c8ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5fa81ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def validate_model(W, b, X_test, y_test):\n",
    "    y_pred = predict(W, b, X_test)\n",
    "    return roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "366f5cb1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7094805c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc=0.9878807730101539\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the data\n",
    "x1, _ = breast_cancer(party_id=1, train=True)\n",
    "x2, y = breast_cancer(party_id=2, train=True)\n",
    "\n",
    "# Hyperparameter\n",
    "W = jnp.zeros((30,))\n",
    "b = 0.0\n",
    "epochs = 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# Train the model\n",
    "W, b = fit(W, b, x1, x2, y, epochs=10, learning_rate=1e-2)\n",
    "\n",
    "# Validate the model\n",
    "X_test, y_test = breast_cancer(train=False)\n",
    "auc = validate_model(W, b, X_test, y_test)\n",
    "print(f'auc={auc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80242142",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As you can see, the warning message\n",
    "\n",
    ">No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
    "\n",
    "doesn't appear, which indicate the jax run the code in GPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f57b47e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import SecretFlow to verify that no errors are reported in this environemnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import secretflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "default",
   "language": "python",
   "display_name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}