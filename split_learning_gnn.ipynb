{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc29a353-e0ea-42ed-bd17-d9efb998b8be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Split Learning for Graph Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34cc94bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ">The following codes are demos only. It's **NOT for production** due to system security concerns, please **DO NOT** use it directly in production."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e4b05c2-ac8a-4436-9abe-95a335c34947",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Create two participant alice and bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67a0f4bb-8522-4b91-8fd3-28dd7dee0641",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of SecretFlow: 1.4.0.dev20240105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 08:24:25,692\tWARNING services.py:1732 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 3300155392 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.22gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-01-10 08:24:25,874\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print('The version of SecretFlow: {}'.format(sf.__version__))\n",
    "\n",
    "# In case you got a running secetflow runtime already.\n",
    "sf.shutdown()\n",
    "\n",
    "sf.init(parties=['alice', 'bob'], address='local')\n",
    "\n",
    "alice, bob = sf.PYU('alice'), sf.PYU('bob')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d589dac-2670-40fa-b33c-4abb86db63b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52b1f363-ff2e-4d89-a3d6-7fb2e9c69f83",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The cora dataset\n",
    "The [cora](https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz) dataset has two tap-separated files: `cora.cites` and `cora.content`.\n",
    "\n",
    "- The `cora.cites` includes the citation records with two columns: cited_paper_id (target) and citing_paper_id (source).\n",
    "- The `cora.content` includes the paper content records with 1,435 columns: paper_id, subject, and 1,433 binary features.\n",
    "\n",
    "Let us use the partitioned cora dataset, which is already a built-in dataset of SecretFlow.\n",
    "\n",
    "- The train set includes 140 cited_paper_ids.\n",
    "- The test set includes 1000 cited_paper_ids.\n",
    "- The valid set includes 500 cited_paper_ids."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b5db30b-0ed7-4cf4-b2bb-b887a9d3fb3f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Split the dataset\n",
    "\n",
    "Let us split the dataset for split learning.\n",
    "\n",
    "- Alice holds the 1~716 features, and bob holds the left.\n",
    "- Alice holds all label.\n",
    "- Alice and bob hold all edges both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff444d11-d754-43cc-83d9-e11d41bb0a50",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70381/2341436718.py:27: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  objects.append(pickle.load(f, encoding='latin1'))\n",
      "/tmp/ipykernel_70381/2341436718.py:38: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  edge = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import zipfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from secretflow.utils.simulation.datasets import dataset\n",
    "from secretflow.data.ndarray import load\n",
    "\n",
    "\n",
    "def load_cora():\n",
    "    dataset_zip = dataset('cora')\n",
    "    extract_path = str(Path(dataset_zip).parent)\n",
    "    with zipfile.ZipFile(dataset_zip, 'r') as zip_f:\n",
    "        zip_f.extractall(extract_path)\n",
    "\n",
    "    file_names = [\n",
    "        os.path.join(extract_path, f'ind.cora.{name}')\n",
    "        for name in ['y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "    ]\n",
    "\n",
    "    objects = []\n",
    "    for name in file_names:\n",
    "        with open(name, 'rb') as f:\n",
    "            objects.append(pickle.load(f, encoding='latin1'))\n",
    "\n",
    "    y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "\n",
    "    with open(os.path.join(extract_path, f\"ind.cora.test.index\"), 'r') as f:\n",
    "        test_idx_reorder = f.readlines()\n",
    "    test_idx_reorder = list(map(lambda s: int(s.strip()), test_idx_reorder))\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "    nodes = scipy.sparse.vstack((allx, tx)).tolil()\n",
    "    nodes[test_idx_reorder, :] = nodes[test_idx_range, :]\n",
    "    edge = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "    edge = edge.toarray() + np.eye(edge.shape[1])\n",
    "\n",
    "    labels = np.vstack((ally, ty))\n",
    "    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "    idx_test = test_idx_range.tolist()\n",
    "    idx_train = range(len(y))\n",
    "    idx_val = range(len(y), len(y) + 500)\n",
    "\n",
    "    def sample_mask(idx, length):\n",
    "        mask = np.zeros(length)\n",
    "        mask[idx] = 1\n",
    "        return np.array(mask, dtype=bool)\n",
    "\n",
    "    idx_train = sample_mask(idx_train, labels.shape[0])\n",
    "    idx_val = sample_mask(idx_val, labels.shape[0])\n",
    "    idx_test = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "    y_train = np.zeros(labels.shape)\n",
    "    y_val = np.zeros(labels.shape)\n",
    "    y_test = np.zeros(labels.shape)\n",
    "    y_train[idx_train, :] = labels[idx_train, :]\n",
    "    y_val[idx_val, :] = labels[idx_val, :]\n",
    "    y_test[idx_test, :] = labels[idx_test, :]\n",
    "\n",
    "    nodes = nodes.toarray()\n",
    "    features_split_pos = round(nodes.shape[1] / 2)\n",
    "    nodes_alice, nodes_bob = (\n",
    "        nodes[:, :features_split_pos],\n",
    "        nodes[:, features_split_pos:],\n",
    "    )\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    saved_files = [\n",
    "        os.path.join(temp_dir, name)\n",
    "        for name in [\n",
    "            'edge.npy',\n",
    "            'x_alice.npy',\n",
    "            'x_bob.npy',\n",
    "            'y_train.npy',\n",
    "            'y_val.npy',\n",
    "            'y_test.npy',\n",
    "            'idx_train.npy',\n",
    "            'idx_val.npy',\n",
    "            'idx_test.npy',\n",
    "        ]\n",
    "    ]\n",
    "    np.save(saved_files[0], edge)\n",
    "    np.save(saved_files[1], nodes_alice)\n",
    "    np.save(saved_files[2], nodes_bob)\n",
    "    np.save(saved_files[3], y_train)\n",
    "    np.save(saved_files[4], y_val)\n",
    "    np.save(saved_files[5], y_test)\n",
    "    np.save(saved_files[6], idx_train)\n",
    "    np.save(saved_files[7], idx_val)\n",
    "    np.save(saved_files[8], idx_test)\n",
    "    return saved_files\n",
    "\n",
    "\n",
    "saved_files = load_cora()\n",
    "\n",
    "edge = load({alice: saved_files[0], bob: saved_files[0]})\n",
    "features = load({alice: saved_files[1], bob: saved_files[2]})\n",
    "Y_train = load({alice: saved_files[3]})\n",
    "Y_val = load({alice: saved_files[4]})\n",
    "Y_test = load({alice: saved_files[5]})\n",
    "idx_train = load({alice: saved_files[6]})\n",
    "idx_val = load({alice: saved_files[7]})\n",
    "idx_test = load({alice: saved_files[8]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acc9a773",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By the way, since cora is a built-in dataset of SecretFlow, you can just run the following snippet to replace the codes above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50100f9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default/lib/python3.8/site-packages/secretflow/utils/simulation/datasets.py:435: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  edge_sparse = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n"
     ]
    }
   ],
   "source": [
    "from secretflow.utils.simulation.datasets import load_cora\n",
    "\n",
    "(edge, features, Y_train, Y_val, Y_test, idx_train, idx_val, idx_test) = load_cora(\n",
    "    [alice, bob]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd373dcf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build a Graph Neural Network Model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5250d2c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Implement a graph convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02de8521",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import constraints, initializers, regularizers\n",
    "from tensorflow.keras.layers import Dropout, Layer, LeakyReLU\n",
    "\n",
    "\n",
    "class GraphAttention(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        F_,\n",
    "        attn_heads=1,\n",
    "        attn_heads_reduction='average',  # {'concat', 'average'}\n",
    "        dropout_rate=0.5,\n",
    "        activation='relu',\n",
    "        use_bias=True,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        attn_kernel_initializer='glorot_uniform',\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        attn_kernel_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        attn_kernel_constraint=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if attn_heads_reduction not in {'concat', 'average'}:\n",
    "            raise ValueError('Possbile reduction methods: concat, average')\n",
    "\n",
    "        self.F_ = F_  # Number of output features (F' in the paper)\n",
    "        self.attn_heads = attn_heads  # Number of attention heads (K in the paper)\n",
    "        self.attn_heads_reduction = attn_heads_reduction\n",
    "        self.dropout_rate = dropout_rate  # Internal dropout rate\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.attn_kernel_initializer = initializers.get(attn_kernel_initializer)\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.attn_kernel_regularizer = regularizers.get(attn_kernel_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.attn_kernel_constraint = constraints.get(attn_kernel_constraint)\n",
    "        self.supports_masking = False\n",
    "\n",
    "        # Populated by build()\n",
    "        self.kernels = []  # Layer kernels for attention heads\n",
    "        self.biases = []  # Layer biases for attention heads\n",
    "        self.attn_kernels = []  # Attention kernels for attention heads\n",
    "\n",
    "        if attn_heads_reduction == 'concat':\n",
    "            # Output will have shape (..., K * F')\n",
    "            self.output_dim = self.F_ * self.attn_heads\n",
    "        else:\n",
    "            # Output will have shape (..., F')\n",
    "            self.output_dim = self.F_\n",
    "\n",
    "        super(GraphAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 2\n",
    "        F = input_shape[0][-1]\n",
    "\n",
    "        # Initialize weights for each attention head\n",
    "        for head in range(self.attn_heads):\n",
    "            # Layer kernel\n",
    "            kernel = self.add_weight(\n",
    "                shape=(F, self.F_),\n",
    "                initializer=self.kernel_initializer,\n",
    "                regularizer=self.kernel_regularizer,\n",
    "                constraint=self.kernel_constraint,\n",
    "                name='kernel_{}'.format(head),\n",
    "            )\n",
    "            self.kernels.append(kernel)\n",
    "\n",
    "            # # Layer bias\n",
    "            if self.use_bias:\n",
    "                bias = self.add_weight(\n",
    "                    shape=(self.F_,),\n",
    "                    initializer=self.bias_initializer,\n",
    "                    regularizer=self.bias_regularizer,\n",
    "                    constraint=self.bias_constraint,\n",
    "                    name='bias_{}'.format(head),\n",
    "                )\n",
    "                self.biases.append(bias)\n",
    "\n",
    "            # Attention kernels\n",
    "            attn_kernel_self = self.add_weight(\n",
    "                shape=(self.F_, 1),\n",
    "                initializer=self.attn_kernel_initializer,\n",
    "                regularizer=self.attn_kernel_regularizer,\n",
    "                constraint=self.attn_kernel_constraint,\n",
    "                name='attn_kernel_self_{}'.format(head),\n",
    "            )\n",
    "            attn_kernel_neighs = self.add_weight(\n",
    "                shape=(self.F_, 1),\n",
    "                initializer=self.attn_kernel_initializer,\n",
    "                regularizer=self.attn_kernel_regularizer,\n",
    "                constraint=self.attn_kernel_constraint,\n",
    "                name='attn_kernel_neigh_{}'.format(head),\n",
    "            )\n",
    "            self.attn_kernels.append([attn_kernel_self, attn_kernel_neighs])\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = inputs[0]  # Node features (N x F)\n",
    "        A = inputs[1]  # Adjacency matrix (N x N)\n",
    "\n",
    "        outputs = []\n",
    "        for head in range(self.attn_heads):\n",
    "            kernel = self.kernels[head]  # W in the paper (F x F')\n",
    "            attention_kernel = self.attn_kernels[\n",
    "                head\n",
    "            ]  # Attention kernel a in the paper (2F' x 1)\n",
    "\n",
    "            # Compute inputs to attention network\n",
    "            features = K.dot(X, kernel)  # (N x F')\n",
    "\n",
    "            # Compute feature combinations\n",
    "            # Note: [[a_1], [a_2]]^T [[Wh_i], [Wh_2]] = [a_1]^T [Wh_i] + [a_2]^T [Wh_j]\n",
    "            attn_for_self = K.dot(\n",
    "                features, attention_kernel[0]\n",
    "            )  # (N x 1), [a_1]^T [Wh_i]\n",
    "            attn_for_neighs = K.dot(\n",
    "                features, attention_kernel[1]\n",
    "            )  # (N x 1), [a_2]^T [Wh_j]\n",
    "\n",
    "            # Attention head a(Wh_i, Wh_j) = a^T [[Wh_i], [Wh_j]]\n",
    "            dense = attn_for_self + K.transpose(\n",
    "                attn_for_neighs\n",
    "            )  # (N x N) via broadcasting\n",
    "\n",
    "            # Add nonlinearty\n",
    "            dense = LeakyReLU(alpha=0.2)(dense)\n",
    "\n",
    "            # Mask values before activation (Vaswani et al., 2017)\n",
    "            mask = -10e9 * (1.0 - A)\n",
    "            dense += mask\n",
    "\n",
    "            # Apply softmax to get attention coefficients\n",
    "            dense = K.softmax(dense)  # (N x N)\n",
    "\n",
    "            # Apply dropout to features and attention coefficients\n",
    "            dropout_attn = Dropout(self.dropout_rate)(dense)  # (N x N)\n",
    "            dropout_feat = Dropout(self.dropout_rate)(features)  # (N x F')\n",
    "\n",
    "            # Linear combination with neighbors' features\n",
    "            node_features = K.dot(dropout_attn, dropout_feat)  # (N x F')\n",
    "\n",
    "            if self.use_bias:\n",
    "                node_features = K.bias_add(node_features, self.biases[head])\n",
    "\n",
    "            # Add output of attention head to final output\n",
    "            outputs.append(node_features)\n",
    "\n",
    "        # Aggregate the heads' output according to the reduction method\n",
    "        if self.attn_heads_reduction == 'concat':\n",
    "            output = K.concatenate(outputs)  # (N x KF')\n",
    "        else:\n",
    "            output = K.mean(K.stack(outputs), axis=0)  # N x F')\n",
    "\n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = input_shape[0][0], self.output_dim\n",
    "        return output_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update(\n",
    "            {\n",
    "                'attn_heads': self.attn_heads,\n",
    "                'attn_heads_reduction': self.attn_heads_reduction,\n",
    "                'F_': self.F_,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27038f11",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Implement a fuse net\n",
    "The fuse model is used in the party with the label. It works as follows:\n",
    "1. Use the concated node embeddings to generat the final node embeddings.\n",
    "2. Feed the node embeddings in a Softmax layer to predict the node class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "543b6a6b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ServerNet(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel: int,\n",
    "        hidden_size: int,\n",
    "        num_layer: int,\n",
    "        num_class: int,\n",
    "        dropout: float,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(ServerNet, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.num_layer = num_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_channel = in_channel\n",
    "        self.dropout = dropout\n",
    "        self.layers = []\n",
    "        super(ServerNet, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.layers.append(\n",
    "            tf.keras.layers.Dense(self.hidden_size, input_shape=(self.in_channel,))\n",
    "        )\n",
    "        for i in range(self.num_layer - 2):\n",
    "            self.layers.append(\n",
    "                tf.keras.layers.Dense(self.hidden_size, input_shape=(self.hidden_size,))\n",
    "            )\n",
    "        self.layers.append(\n",
    "            tf.keras.layers.Dense(self.num_class, input_shape=(self.hidden_size,))\n",
    "        )\n",
    "\n",
    "        super(ServerNet, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        x = Dropout(self.dropout)(x)\n",
    "        for i in range(self.num_layer):\n",
    "            x = Dropout(self.dropout)(x)\n",
    "            x = self.layers[i](x)\n",
    "\n",
    "        return K.softmax(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = self.hidden_size, self.output_dim\n",
    "        return output_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update(\n",
    "            {\n",
    "                'in_channel': self.in_channel,\n",
    "                'hidden_size': self.hidden_size,\n",
    "                'num_layer': self.num_layer,\n",
    "                'num_class': self.num_class,\n",
    "                'dropout': self.dropout,\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec3ef65f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build the base model\n",
    "The base model is used in each party to generate node embeddings. It applys one graph convolutional layer to produce node embeddings.\n",
    "\n",
    "The node embeddings of all parties are then transfered to the party with labels for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64356e46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def create_base_model(\n",
    "    input_shape, n_hidden, l2_reg, num_heads, dropout_rate, learning_rate\n",
    "):\n",
    "    def base_model():\n",
    "        feature_input = tf.keras.Input(shape=(input_shape[1],))\n",
    "        graph_input = tf.keras.Input(shape=(input_shape[0],))\n",
    "        regular = tf.keras.regularizers.l2(l2_reg)\n",
    "        outputs = GraphAttention(\n",
    "            F_=n_hidden,\n",
    "            attn_heads=num_heads,\n",
    "            attn_heads_reduction='average',  # {'concat', 'average'}\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation='relu',\n",
    "            use_bias=True,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            bias_initializer='zeros',\n",
    "            attn_kernel_initializer='glorot_uniform',\n",
    "            kernel_regularizer=regular,\n",
    "            bias_regularizer=None,\n",
    "            attn_kernel_regularizer=None,\n",
    "            activity_regularizer=None,\n",
    "            kernel_constraint=None,\n",
    "            bias_constraint=None,\n",
    "            attn_kernel_constraint=None,\n",
    "        )([feature_input, graph_input])\n",
    "        # outputs = tf.keras.layers.Flatten()(outputs)\n",
    "        model = Model(inputs=[feature_input, graph_input], outputs=outputs)\n",
    "        model._name = \"embed_model\"\n",
    "        # Compile model\n",
    "        model.summary()\n",
    "        metrics = ['acc']\n",
    "        optimizer = tf.keras.optimizers.get(\n",
    "            {\n",
    "                'class_name': 'adam',\n",
    "                'config': {'learning_rate': learning_rate},\n",
    "            }\n",
    "        )\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            weighted_metrics=metrics,\n",
    "            optimizer=optimizer,\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    return base_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3300e7c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build the fuse model\n",
    "The fuse model concat the node embeddings from all parties as input. It works only in the party with the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8a58cd6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def create_fuse_model(hidden_units, hidden_size, n_classes, layer_num, learning_rate):\n",
    "    def fuse_model():\n",
    "        inputs = [keras.Input(shape=size) for size in hidden_units]\n",
    "        x = layers.concatenate(inputs)\n",
    "        input_shape = x.shape[-1]\n",
    "        y_pred = ServerNet(\n",
    "            in_channel=input_shape,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layer=layer_num,\n",
    "            num_class=n_classes,\n",
    "            dropout=0.0,\n",
    "        )(x)\n",
    "        # Create the model.\n",
    "        model = keras.Model(inputs=inputs, outputs=y_pred, name=\"fuse_model\")\n",
    "        model.summary()\n",
    "        metrics = ['acc']\n",
    "        optimizer = tf.keras.optimizers.get(\n",
    "            {\n",
    "                'class_name': 'adam',\n",
    "                'config': {'learning_rate': learning_rate},\n",
    "            }\n",
    "        )\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            weighted_metrics=metrics,\n",
    "            optimizer=optimizer,\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    return fuse_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25e7182",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train GNN model with split learning\n",
    "\n",
    "Let us build a split learning model for training. \n",
    "\n",
    "Alice who has the label holds a base model and a fuse model, while bob holds a base model only.\n",
    "\n",
    "The whole model structure is as follow\n",
    "\n",
    "<img alt=\"split_learning_gnn_model.png\" src=\"resources/split_gnn.svg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df19c1eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.sl.backend.tensorflow.sl_base.PYUSLTFModel'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.sl.backend.tensorflow.sl_base.PYUSLTFModel'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "from secretflow.ml.nn import SLModel\n",
    "\n",
    "hidden_size = 256\n",
    "n_classes = 7\n",
    "attn_heads = 2\n",
    "layer_num = 3\n",
    "learning_rate = 1e-3\n",
    "dropout_rate = 0.0\n",
    "l2_reg = 0.1\n",
    "num_heads = 4\n",
    "epochs = 10\n",
    "optimizer = 'adam'\n",
    "\n",
    "partition_shapes = features.partition_shape()\n",
    "\n",
    "input_shape_alice = partition_shapes[alice]\n",
    "input_shape_bob = partition_shapes[bob]\n",
    "\n",
    "sl_model = SLModel(\n",
    "    base_model_dict={\n",
    "        alice: create_base_model(\n",
    "            input_shape_alice,\n",
    "            hidden_size,\n",
    "            l2_reg,\n",
    "            num_heads,\n",
    "            dropout_rate,\n",
    "            learning_rate,\n",
    "        ),\n",
    "        bob: create_base_model(\n",
    "            input_shape_bob,\n",
    "            hidden_size,\n",
    "            l2_reg,\n",
    "            num_heads,\n",
    "            dropout_rate,\n",
    "            learning_rate,\n",
    "        ),\n",
    "    },\n",
    "    device_y=alice,\n",
    "    model_fuse=create_fuse_model(\n",
    "        [hidden_size, hidden_size], hidden_size, n_classes, layer_num, learning_rate\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8fe270c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078727f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:SL Train Params: {'self': <secretflow.ml.nn.sl.sl_model.SLModel object at 0x7f2487db7970>, 'x': [FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f251deeec10>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7f251deeec40>}, partition_way=<PartitionWay.VERTICAL: 'vertical'>), FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f251deee5e0>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7f251deee820>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>)], 'y': FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f251deee730>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>), 'batch_size': 2708, 'epochs': 10, 'verbose': 1, 'callbacks': None, 'validation_data': ([FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f251deeec10>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7f251deeec40>}, partition_way=<PartitionWay.VERTICAL: 'vertical'>), FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f251deee5e0>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7f251deee820>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>)], FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f251deee3a0>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>), FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f251df79ee0>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>)), 'shuffle': False, 'sample_weight': FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f251deee400>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>), 'validation_freq': 1, 'dp_spent_step_freq': None, 'dataset_builder': None, 'audit_log_params': {}, 'early_stopping_batch_step': 0, 'early_stopping_warmup_step': 0, 'random_seed': 89165, 'audit_log_dir': None}\n",
      "\u001B[2m\u001B[36m(pid=83901)\u001B[0m 2024-01-10 08:25:19.800823: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(pid=83903)\u001B[0m 2024-01-10 08:25:20.086832: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(pid=83901)\u001B[0m 2024-01-10 08:25:21.332429: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(pid=83901)\u001B[0m 2024-01-10 08:25:21.332635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(pid=83901)\u001B[0m 2024-01-10 08:25:21.332645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001B[2m\u001B[36m(pid=83903)\u001B[0m 2024-01-10 08:25:21.670426: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(pid=83903)\u001B[0m 2024-01-10 08:25:21.670693: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(pid=83903)\u001B[0m 2024-01-10 08:25:21.670712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m 2024-01-10 08:25:27.572916: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m 2024-01-10 08:25:27.548696: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m /opt/conda/envs/default/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m   warnings.warn(\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m WARNING:tensorflow:AutoGraph could not transform <bound method GraphAttention.call of <__main__.GraphAttention object at 0x7f5341e47190>> and will run it as-is.\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Cause: Unknown node type <gast.gast.Import object at 0x7f53405e6970>\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m /opt/conda/envs/default/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m   warnings.warn(\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m WARNING:tensorflow:AutoGraph could not transform <bound method GraphAttention.call of <__main__.GraphAttention object at 0x7f2e63e4bf10>> and will run it as-is.\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m Cause: Unknown node type <gast.gast.Import object at 0x7f2e60564730>\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m WARNING:tensorflow:AutoGraph could not transform <bound method ServerNet.call of <__main__.ServerNet object at 0x7f5341e9d8b0>> and will run it as-is.\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Cause: Unknown node type <gast.gast.Import object at 0x7f5340101370>\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Model: \"embed_model\"\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m __________________________________________________________________________________________________\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m  Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m ==================================================================================================\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m  input_1 (InputLayer)           [(None, 716)]        0           []                               \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m                                                                                                   \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m  input_2 (InputLayer)           [(None, 2708)]       0           []                               \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m                                                                                                   \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m  graph_attention (GraphAttentio  (None, 256)         736256      ['input_1[0][0]',                \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m  n)                                                               'input_2[0][0]']                \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m                                                                                                   \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m ==================================================================================================\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Total params: 736,256\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Trainable params: 736,256\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Non-trainable params: 0\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m __________________________________________________________________________________________________\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m Model: \"embed_model\"\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m __________________________________________________________________________________________________\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m  Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m ==================================================================================================\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m  input_1 (InputLayer)           [(None, 717)]        0           []                               \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m                                                                                                   \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m  input_2 (InputLayer)           [(None, 2708)]       0           []                               \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m                                                                                                   \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m  graph_attention (GraphAttentio  (None, 256)         737280      ['input_1[0][0]',                \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m  n)                                                               'input_2[0][0]']                \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m                                                                                                   \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m ==================================================================================================\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m Total params: 737,280\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m Trainable params: 737,280\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m Non-trainable params: 0\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83903)\u001B[0m __________________________________________________________________________________________________\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Model: \"fuse_model\"\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m __________________________________________________________________________________________________\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m  Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m ==================================================================================================\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m  input_3 (InputLayer)           [(None, 256)]        0           []                               \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m                                                                                                   \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m  input_4 (InputLayer)           [(None, 256)]        0           []                               \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m                                                                                                   \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m  concatenate (Concatenate)      (None, 512)          0           ['input_3[0][0]',                \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m                                                                   'input_4[0][0]']                \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m                                                                                                   \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m  server_net_1 (ServerNet)       (None, 7)            198919      ['concatenate[0][0]']            \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m                                                                                                   \n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m ==================================================================================================\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Total params: 198,919\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Trainable params: 198,919\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m Non-trainable params: 0\n",
      "\u001B[2m\u001B[36m(PYUSLTFModel pid=83901)\u001B[0m __________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 08:25:32.486149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-10 08:25:32.486395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 08:25:32.486527: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 08:25:32.486774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-01-10 08:25:32.486979: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 08:25:32.487097: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 08:25:32.487140: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Train Processing: :   0%|          | 0/1 [00:04<?, ?it/s]\u001B[2m\u001B[36m(_run pid=77783)\u001B[0m 2024-01-10 08:25:34.356910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77783)\u001B[0m 2024-01-10 08:25:35.677494: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77783)\u001B[0m 2024-01-10 08:25:35.677640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77783)\u001B[0m 2024-01-10 08:25:35.677651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001B[2m\u001B[36m(_run pid=77783)\u001B[0m 2024-01-10 08:25:40.413950: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Train Processing: :   0%|          | 0/1 [00:15<?, ?it/s, {'train_loss': 301.86475, 'train_acc': 0.17142858, 'val_loss': 290.7395, 'val_acc': 0.296}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(_run pid=77755)\u001B[0m 2024-01-10 08:25:45.117566: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77755)\u001B[0m 2024-01-10 08:25:46.577136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77755)\u001B[0m 2024-01-10 08:25:46.577404: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77755)\u001B[0m 2024-01-10 08:25:46.577427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001B[2m\u001B[36m(_run pid=77755)\u001B[0m 2024-01-10 08:25:51.631512: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Train Processing: :   0%|          | 0/1 [00:08<?, ?it/s, {'train_loss': 290.48343, 'train_acc': 0.40714285, 'val_loss': 279.65277, 'val_acc': 0.368}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(_run pid=77773)\u001B[0m 2024-01-10 08:25:53.231782: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77773)\u001B[0m 2024-01-10 08:25:54.978038: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77773)\u001B[0m 2024-01-10 08:25:54.978184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77773)\u001B[0m 2024-01-10 08:25:54.978201: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001B[2m\u001B[36m(_run pid=77773)\u001B[0m 2024-01-10 08:26:00.380318: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Train Processing: :   0%|          | 0/1 [00:08<?, ?it/s, {'train_loss': 279.39856, 'train_acc': 0.6571429, 'val_loss': 268.86377, 'val_acc': 0.428}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s, {'train_loss': 268.612, 'train_acc': 0.70714283, 'val_loss': 258.37225, 'val_acc': 0.472}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s, {'train_loss': 258.12354, 'train_acc': 0.73571426, 'val_loss': 248.17697, 'val_acc': 0.512}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:02<?, ?it/s, {'train_loss': 247.93192, 'train_acc': 0.8, 'val_loss': 238.2767, 'val_acc': 0.568}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(_run pid=77649)\u001B[0m 2024-01-10 08:26:04.743663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77649)\u001B[0m 2024-01-10 08:26:06.434447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77649)\u001B[0m 2024-01-10 08:26:06.434602: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001B[2m\u001B[36m(_run pid=77649)\u001B[0m 2024-01-10 08:26:06.434618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001B[2m\u001B[36m(_run pid=77649)\u001B[0m 2024-01-10 08:26:11.453468: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Train Processing: :   0%|          | 0/1 [00:07<?, ?it/s, {'train_loss': 238.03577, 'train_acc': 0.85714287, 'val_loss': 228.66953, 'val_acc': 0.61}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s, {'train_loss': 228.43321, 'train_acc': 0.87142855, 'val_loss': 219.35294, 'val_acc': 0.632}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s, {'train_loss': 219.12158, 'train_acc': 0.8857143, 'val_loss': 210.32394, 'val_acc': 0.652}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s, {'train_loss': 210.09789, 'train_acc': 0.9142857, 'val_loss': 201.57928, 'val_acc': 0.67}]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'train_loss': [301.86475,\n  290.48343,\n  279.39856,\n  268.612,\n  258.12354,\n  247.93192,\n  238.03577,\n  228.43321,\n  219.12158,\n  210.09789],\n 'train_acc': [0.17142858,\n  0.40714285,\n  0.6571429,\n  0.70714283,\n  0.73571426,\n  0.8,\n  0.85714287,\n  0.87142855,\n  0.8857143,\n  0.9142857],\n 'val_loss': [290.7395,\n  279.65277,\n  268.86377,\n  258.37225,\n  248.17697,\n  238.2767,\n  228.66953,\n  219.35294,\n  210.32394,\n  201.57928],\n 'val_acc': [0.296,\n  0.368,\n  0.428,\n  0.472,\n  0.512,\n  0.568,\n  0.61,\n  0.632,\n  0.652,\n  0.67]}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl_model.fit(\n",
    "    x=[features, edge],\n",
    "    y=Y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=input_shape_alice[0],\n",
    "    sample_weight=idx_train,\n",
    "    validation_data=([features, edge], Y_val, idx_val),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09de4553",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Examine the GNN model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dce891f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate Processing: :   0%|          | 0/1 [00:00<?, ?it/s, loss=202, acc=0.7]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'loss': 201.85703, 'acc': 0.7}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl_model.evaluate(\n",
    "    x=[features, edge],\n",
    "    y=Y_test,\n",
    "    batch_size=input_shape_alice[0],\n",
    "    sample_weight=idx_test,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b357a1ff-9674-4258-87d7-9278d3c0406d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ceb119b1-dd74-4ad1-9c00-69b0928e125f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this tutorial, we demonstrate how to train graph neural network with split learning. This is a very basic implementation and there are some works we will explore in the future:\n",
    "\n",
    "- SGD on large graphs: in the example above, in each training step, we have to do `prepare`, `aggregate` and `update` on whole graph, which is extremely computation intensive. We should perform stochastic minibatch training to reduce computation and memory comsumption.\n",
    "- Partially aligned graphs: in the example above, parties must have same nodes set which may not be satisfied in real cases. We want to explore the case where all parties have common subset nodes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "default",
   "language": "python",
   "display_name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae1fdd5fd034b7d694352220485921694ff89198520409089b4646721fce11ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}