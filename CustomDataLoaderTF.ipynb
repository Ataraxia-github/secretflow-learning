{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b6b37c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using Custom DataBuilder in SecretFlow (TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e57a23",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following codes are demos only. It's **NOT for production** due to system security concerns, please **DO NOT** use it directly in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8528a86e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this tutorial, we will show you how to load data and train model using the custom DataBuilder schema in the multi-party secure environment of SecretFlow.\n",
    "This tutorial will use the image classification task of the Flower dataset to introduce, how to use the custom DataBuilder to complete federated learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e55b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08ecd6d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812c6aea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of SecretFlow: 1.4.0.dev20240105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 04:28:44,891\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print('The version of SecretFlow: {}'.format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "sf.init(['alice', 'bob', 'charlie'], address=\"local\", log_to_driver=False)\n",
    "alice, bob, charlie = sf.PYU('alice'), sf.PYU('bob'), sf.PYU('charlie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c38ba4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Interface Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509e5461",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We support custom DataBuilder reads in SecretFlow's `FLModel` to make it easier for users to handle data inputs more flexibly according to their needs.\n",
    "Let's use an example to demonstrate how to use the custom DataBuilder for federated model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff157baf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Steps to use DataBuilder:\n",
    "\n",
    "1. Use the single-machine version engine (TensorFlow, PyTorch) to develop and get the Builder function of the Dataset.\n",
    "2. Wrap the Builder functions of each party to get `create_dataset_builder` function. *Note: The dataset_builder needs to pass in the stage parameter.*\n",
    "3. Build the data_builder_dict [PYU, dataset_builder].\n",
    "4. Pass the obtained data_builder_dict to the `dataset_builder` of the `fit` function. At the same time, the x parameter position is passed into the required input in dataset_builder (eg: the input passed in this example is the actual image path used)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad75fd6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Using DataBuilder in FLModel requires a pre-defined `data_builder_dict`. Need to be able to return `tf.dataset` and `steps_per_epoch`. And the steps_per_epoch returned by all parties must be consistent.\n",
    "```python\n",
    "data_builder_dict = \n",
    "        {\n",
    "            alice: create_alice_dataset_builder(\n",
    "                batch_size=32,\n",
    "            ), # create_alice_dataset_builder must return (Dataset, steps_per_epoch)\n",
    "            bob: create_bob_dataset_builder(\n",
    "                batch_size=32,\n",
    "            ), # create_bob_dataset_builder must return (Dataset, steps_per_epochstep_per_epochs)\n",
    "        }\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b0faf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ffc09e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Flower Dataset Introduction: The Flower dataset consists of 4323 color images of 5 different types of flowers (daisy, dandelion, rose, sunflower, and tulip). Each flower has images from multiple angles and different lighting conditions, and the resolution of each image is 320x240.\n",
    "This dataset is commonly used for training and testing of image classification and machine learning algorithms. The number of each category in the dataset is as follows: daisy (633), dandelion (898), rose (641), sunflower (699), and tulip (852).\n",
    "\n",
    "Download link: [http://download.tensorflow.org/example_images/flower_photos.tgz](http://download.tensorflow.org/example_images/flower_photos.tgz)\n",
    "\n",
    "<img alt=\"flower_dataset_demo.png\" src=\"resources/flower_dataset_demo.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f5d14",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Download Data and Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9720cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 04:32:10.587955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:32:12.079306: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:32:12.079459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:32:12.079465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://secretflow-data.oss-accelerate.aliyuncs.com/datasets/tf_flowers/flower_photos.tgz\n",
      "67588319/67588319 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import tensorflow as tf\n",
    "\n",
    "_temp_dir = tempfile.mkdtemp()\n",
    "path_to_flower_dataset = tf.keras.utils.get_file(\n",
    "    \"flower_photos\",\n",
    "    \"https://secretflow-data.oss-accelerate.aliyuncs.com/datasets/tf_flowers/flower_photos.tgz\",\n",
    "    untar=True,\n",
    "    cache_dir=_temp_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f1057",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next let's start building a custom DataBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d98ab3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Develop DataBuilder with single-machine version engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c81834d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "When we develop DataBuilder, we are free to follow the logic of single-machine development.\n",
    "The purpose is to build a `tf.dataset` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe48fe7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1201 files belonging to 5 classes.\n",
      "Using 961 files for training.\n",
      "Using 240 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 04:33:19.113342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:33:19.113568: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:33:19.113703: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:33:19.113825: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:33:19.114090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:33:19.114205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:33:19.114304: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:33:19.114420: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-01-10 04:33:19.114433: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "batch_size = 32\n",
    "# In this example, we use the TensorFlow interface for development.\n",
    "data_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_to_flower_dataset,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8106f107",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_set = data_set[0]\n",
    "test_set = data_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37dd53fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'> <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_set), type(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4199b24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (32, 180, 180, 3)\n",
      "y.shape = (32,)\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_set))\n",
    "print(f\"x.shape = {x.shape}\")\n",
    "print(f\"y.shape = {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e0c15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Wrap the developed DataBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb0e6d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The DataBuilder we developed needs to be distributed to each execution machine for execution, and we need to wrap them in order to serialize.\n",
    "Note: **FLModel requires the incoming DataBuilder return two results (data_set, steps_per_epoch).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d36bee75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset_builder(\n",
    "    batch_size=32,\n",
    "):\n",
    "    def dataset_builder(folder_path, stage=\"train\"):\n",
    "        import math\n",
    "\n",
    "        import tensorflow as tf\n",
    "\n",
    "        img_height = 180\n",
    "        img_width = 180\n",
    "        data_set = tf.keras.utils.image_dataset_from_directory(\n",
    "            folder_path,\n",
    "            validation_split=0.2,\n",
    "            subset=\"both\",\n",
    "            seed=123,\n",
    "            image_size=(img_height, img_width),\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        if stage == \"train\":\n",
    "            train_dataset = data_set[0]\n",
    "            train_step_per_epoch = math.ceil(len(data_set[0].file_paths) / batch_size)\n",
    "            return train_dataset, train_step_per_epoch\n",
    "        elif stage == \"eval\":\n",
    "            eval_dataset = data_set[1]\n",
    "            eval_step_per_epoch = math.ceil(len(data_set[1].file_paths) / batch_size)\n",
    "            return eval_dataset, eval_step_per_epoch\n",
    "\n",
    "    return dataset_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198128c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Build dataset_builder_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a73a04",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the horizontal scenario, the logic for all parties to process data is the same, so we only need a wrapped DataBuilder construction method.\n",
    "Next we build the `dataset_builder_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c051b566",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_builder_dict = {\n",
    "    alice: create_dataset_builder(\n",
    "        batch_size=32,\n",
    "    ),\n",
    "    bob: create_dataset_builder(\n",
    "        batch_size=32,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e36c7d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. After get dataset_builder_dict, we can pass it into the model for use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602707d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we define the model and use the custom data constructed above for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feea334e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_conv_flower_model(input_shape, num_classes, name='model'):\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "\n",
    "        # Create model\n",
    "\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_shape),\n",
    "                tf.keras.layers.Rescaling(1.0 / 255),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(128, activation='relu'),\n",
    "                tf.keras.layers.Dense(num_classes),\n",
    "            ]\n",
    "        )\n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer='adam',\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    return create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60414cb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from secretflow.ml.nn import FLModel\n",
    "from secretflow.security.aggregation import SecureAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f368538f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.security.aggregation.secure_aggregator._Masker'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.security.aggregation.secure_aggregator._Masker'> with party bob.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.fl.backend.tensorflow.strategy.fed_avg_w.PYUFedAvgW'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.fl.backend.tensorflow.strategy.fed_avg_w.PYUFedAvgW'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "device_list = [alice, bob]\n",
    "aggregator = SecureAggregator(charlie, [alice, bob])\n",
    "\n",
    "# prepare model\n",
    "num_classes = 5\n",
    "input_shape = (180, 180, 3)\n",
    "\n",
    "# keras model\n",
    "model = create_conv_flower_model(input_shape, num_classes)\n",
    "\n",
    "\n",
    "fed_model = FLModel(\n",
    "    device_list=device_list,\n",
    "    model=model,\n",
    "    aggregator=aggregator,\n",
    "    backend=\"tensorflow\",\n",
    "    strategy=\"fed_avg_w\",\n",
    "    random_seed=1234,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d97af9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The input of our constructed dataset builder is the path of the image dataset, so we need to set the input data as a `Dict` here.\n",
    "```python\n",
    "data = {\n",
    "    alice: folder_path_of_alice,\n",
    "    bob: folder_path_of_bob\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de4b659a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:FL Train Params: {'x': {PYURuntime(alice): '/tmp/tmppc9qcf6d/datasets/flower_photos', PYURuntime(bob): '/tmp/tmppc9qcf6d/datasets/flower_photos'}, 'y': None, 'batch_size': 32, 'batch_sampling_rate': None, 'epochs': 5, 'verbose': 1, 'callbacks': None, 'validation_data': {PYURuntime(alice): '/tmp/tmppc9qcf6d/datasets/flower_photos', PYURuntime(bob): '/tmp/tmppc9qcf6d/datasets/flower_photos'}, 'shuffle': False, 'class_weight': None, 'sample_weight': None, 'validation_freq': 1, 'aggregate_freq': 2, 'label_decoder': None, 'max_batch_size': 20000, 'prefetch_buffer_size': None, 'sampler_method': 'batch', 'random_seed': 1234, 'dp_spent_step_freq': 1, 'audit_log_dir': None, 'dataset_builder': {PYURuntime(alice): <function create_dataset_builder.<locals>.dataset_builder at 0x7f3cbc220b80>, PYURuntime(bob): <function create_dataset_builder.<locals>.dataset_builder at 0x7f3cbc2201f0>}, 'wait_steps': 100, 'self': <secretflow.ml.nn.fl.fl_model.FLModel object at 0x7f3b8c3ba7f0>}\n"
     ]
    },
    {
     "ename": "RayActorError",
     "evalue": "The actor died unexpectedly before finishing this task.\n\tclass_name: PYUFedAvgW\n\tactor_id: 5ebf6c7806b37757a4b69de601000000\n\tpid: 36084\n\tnamespace: 13a967af-3abe-4d71-b7aa-bc18c29ecda8\n\tip: 10.0.0.1\nThe actor is dead because its worker process has died. Worker exit type: NODE_OUT_OF_MEMORY Worker exit detail: Task was killed due to the node running low on memory.\nMemory on the node (IP: 10.0.0.1, ID: 8f5c84c306464a98c3ba9b8dae5e28712c0721d689a089df7f8d2ad6) where the task (task ID: ffffffffffffffff5ebf6c7806b37757a4b69de601000000, name=PYUFedAvgW.__init__, pid=36084, memory used=0.26GB) was running was 60.81GB / 64.00GB (0.950137), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 9e105308d3b4420cef48a4baa85a812b50a687a62aa5e8de5ddfc309) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.0.0.1`. To see the logs of the worker, use `ray logs worker-9e105308d3b4420cef48a4baa85a812b50a687a62aa5e8de5ddfc309*out -ip 10.0.0.1. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n4740\t3.29\t/opt/conda/envs/default/bin/python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kerne...\n3956\t1.62\t/opt/conda/envs/default/bin/python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kerne...\n25356\t0.84\t/opt/conda/envs/default/bin/python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kerne...\n32498\t0.75\tray::PYUFedAvgW\n17845\t0.73\t/opt/conda/envs/default/bin/python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kerne...\n32495\t0.65\tray::PYUFedAvgW\n32598\t0.50\tray::PYUFedAvgW\n36080\t0.27\tray::IDLE\n36084\t0.26\tray::IDLE\n125898\t0.20\t/opt/conda/envs/default/bin/python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kerne...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\nThe actor never ran - it was cancelled before it started running.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRayActorError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m data \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      2\u001B[0m     alice: path_to_flower_dataset,\n\u001B[1;32m      3\u001B[0m     bob: path_to_flower_dataset,\n\u001B[1;32m      4\u001B[0m }\n\u001B[0;32m----> 5\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mfed_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43maggregate_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43msampler_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbatch\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1234\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdp_spent_step_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_builder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_builder_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/secretflow/ml/nn/fl/fl_model.py:413\u001B[0m, in \u001B[0;36mFLModel.fit\u001B[0;34m(self, x, y, batch_size, batch_sampling_rate, epochs, verbose, callbacks, validation_data, shuffle, class_weight, sample_weight, validation_freq, aggregate_freq, label_decoder, max_batch_size, prefetch_buffer_size, sampler_method, random_seed, dp_spent_step_freq, audit_log_dir, dataset_builder, wait_steps)\u001B[0m\n\u001B[1;32m    410\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    411\u001B[0m         valid_x, valid_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 413\u001B[0m     train_steps_per_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[43m        \u001B[49m\u001B[43msampling_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_sampling_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    419\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabel_decoder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabel_decoder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprefetch_buffer_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprefetch_buffer_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    424\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdataset_builder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_builder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    427\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(x) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mtype\u001B[39m(y), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y must be same data type\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/secretflow/ml/nn/fl/fl_model.py:179\u001B[0m, in \u001B[0;36mFLModel._handle_file\u001B[0;34m(self, train_dict, label, batch_size, sampling_rate, shuffle, random_seed, epochs, stage, label_decoder, max_batch_size, prefetch_buffer_size, dataset_builder)\u001B[0m\n\u001B[1;32m    170\u001B[0m     steps_per_epoch \u001B[38;5;241m=\u001B[39m worker\u001B[38;5;241m.\u001B[39mbuild_dataset_from_builder(\n\u001B[1;32m    171\u001B[0m         dataset_builder[device],\n\u001B[1;32m    172\u001B[0m         train_dict[device],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    176\u001B[0m         repeat_count\u001B[38;5;241m=\u001B[39mepochs,\n\u001B[1;32m    177\u001B[0m     )\n\u001B[1;32m    178\u001B[0m     steps_per_epochs\u001B[38;5;241m.\u001B[39mappend(steps_per_epoch)\n\u001B[0;32m--> 179\u001B[0m set_steps_per_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[43mreveal\u001B[49m\u001B[43m(\u001B[49m\u001B[43msteps_per_epochs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28mlen\u001B[39m(set_steps_per_epochs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    182\u001B[0m ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msteps_per_epochs of all parties must be same\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    183\u001B[0m steps_per_epoch \u001B[38;5;241m=\u001B[39m set_steps_per_epochs\u001B[38;5;241m.\u001B[39mpop()\n",
      "File \u001B[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/secretflow/device/driver.py:162\u001B[0m, in \u001B[0;36mreveal\u001B[0;34m(func_or_object, heu_encoder)\u001B[0m\n\u001B[1;32m    159\u001B[0m         logging\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGetting teeu data from TEEU \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mparty\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    161\u001B[0m cur_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 162\u001B[0m all_object \u001B[38;5;241m=\u001B[39m \u001B[43msfd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_object_refs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m new_flatten_val \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m flatten_val:\n",
      "File \u001B[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/secretflow/distributed/primitive.py:158\u001B[0m, in \u001B[0;36mget\u001B[0;34m(object_refs)\u001B[0m\n\u001B[1;32m    156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fed\u001B[38;5;241m.\u001B[39mget(object_refs)\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m get_distribution_mode() \u001B[38;5;241m==\u001B[39m DISTRIBUTION_MODE\u001B[38;5;241m.\u001B[39mSIMULATION:\n\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobject_refs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m get_distribution_mode() \u001B[38;5;241m==\u001B[39m DISTRIBUTION_MODE\u001B[38;5;241m.\u001B[39mDEBUG:\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m object_refs\n",
      "File \u001B[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/ray/_private/client_mode_hook.py:105\u001B[0m, in \u001B[0;36mclient_mode_hook.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m is_client_mode_enabled_by_default:\n\u001B[1;32m    104\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(ray, func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/envs/default/lib/python3.8/site-packages/ray/_private/worker.py:2311\u001B[0m, in \u001B[0;36mget\u001B[0;34m(object_refs, timeout)\u001B[0m\n\u001B[1;32m   2309\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m value\u001B[38;5;241m.\u001B[39mas_instanceof_cause()\n\u001B[1;32m   2310\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2311\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m value\n\u001B[1;32m   2313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_individual_id:\n\u001B[1;32m   2314\u001B[0m     values \u001B[38;5;241m=\u001B[39m values[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mRayActorError\u001B[0m: The actor died unexpectedly before finishing this task.\n\tclass_name: PYUFedAvgW\n\tactor_id: 5ebf6c7806b37757a4b69de601000000\n\tpid: 36084\n\tnamespace: 13a967af-3abe-4d71-b7aa-bc18c29ecda8\n\tip: 10.0.0.1\nThe actor is dead because its worker process has died. Worker exit type: NODE_OUT_OF_MEMORY Worker exit detail: Task was killed due to the node running low on memory.\nMemory on the node (IP: 10.0.0.1, ID: 8f5c84c306464a98c3ba9b8dae5e28712c0721d689a089df7f8d2ad6) where the task (task ID: ffffffffffffffff5ebf6c7806b37757a4b69de601000000, name=PYUFedAvgW.__init__, pid=36084, memory used=0.26GB) was running was 60.81GB / 64.00GB (0.950137), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 9e105308d3b4420cef48a4baa85a812b50a687a62aa5e8de5ddfc309) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.0.0.1`. To see the logs of the worker, use `ray logs worker-9e105308d3b4420cef48a4baa85a812b50a687a62aa5e8de5ddfc309*out -ip 10.0.0.1. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n4740\t3.29\t/opt/conda/envs/default/bin/python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kerne...\n3956\t1.62\t/opt/conda/envs/default/bin/python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kerne...\n25356\t0.84\t/opt/conda/envs/default/bin/python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kerne...\n32498\t0.75\tray::PYUFedAvgW\n17845\t0.73\t/opt/conda/envs/default/bin/python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kerne...\n32495\t0.65\tray::PYUFedAvgW\n32598\t0.50\tray::PYUFedAvgW\n36080\t0.27\tray::IDLE\n36084\t0.26\tray::IDLE\n125898\t0.20\t/opt/conda/envs/default/bin/python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kerne...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\nThe actor never ran - it was cancelled before it started running."
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    alice: path_to_flower_dataset,\n",
    "    bob: path_to_flower_dataset,\n",
    "}\n",
    "history = fed_model.fit(\n",
    "    data,\n",
    "    None,\n",
    "    validation_data=data,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    aggregate_freq=2,\n",
    "    sampler_method=\"batch\",\n",
    "    random_seed=1234,\n",
    "    dp_spent_step_freq=1,\n",
    "    dataset_builder=data_builder_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff96a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, you can use your own dataset to try"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "default",
   "language": "python",
   "display_name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}